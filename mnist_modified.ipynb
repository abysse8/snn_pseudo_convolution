{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d61ca3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bindsnet.network import Network\n",
    "from bindsnet.network.nodes import LIFNodes\n",
    "from bindsnet.network.nodes import Input\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.network.monitors import NetworkMonitor\n",
    "from bindsnet.analysis.plotting import plot_spikes, plot_voltages\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import bernoulli, ones, randn\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    "    plot_weights,\n",
    ")\n",
    "#!echo \"./data/MNIST\" >> ./.gitignore ### run once only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "98868f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 500\n",
    "dt = 1\n",
    "num_epochs = 1\n",
    "progress_interval = 10\n",
    "update_interval = 250\n",
    "\n",
    "intensity = 128\n",
    "\n",
    "image_shape = (32, 32)\n",
    "dendrite_field_shape = image_shape\n",
    "num_dendrite_layers = 2\n",
    "dendrite_span = 5 #in pixels\n",
    "\n",
    "seed = 8\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "network = Network(dt=dt, learning=True, batch_size=1, reward_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dae32c",
   "metadata": {},
   "source": [
    "### In this setup, the physical weights between neurons don't change in the short term, only the dendritic feedback stimulation. Hence we first connect the network randomly.\n",
    "\n",
    "# Version 1: Feedback dendrites have unlimited span but make relatively sparse connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "274f7d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology with visual input, light-sensitive neurons, feedback paths:\n",
      "Network(\n",
      "  (simulated input): Input()\n",
      "  (light-receptive neurons): LIFNodes()\n",
      "  (simulated input_to_light-receptive neurons): Connection(\n",
      "    (source): Input()\n",
      "    (target): LIFNodes()\n",
      "  )\n",
      "  (feedback 0): LIFNodes()\n",
      "  (feedback 0_to_light-receptive neurons): Connection(\n",
      "    (source): LIFNodes()\n",
      "    (target): LIFNodes()\n",
      "  )\n",
      "  (feedback 1): LIFNodes()\n",
      "  (feedback 1_to_light-receptive neurons): Connection(\n",
      "    (source): LIFNodes()\n",
      "    (target): LIFNodes()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "connection_prob = 0.3 #probability of any given feedback neuron\n",
    "                      #connecting to any given sensory neuron\n",
    "\n",
    "input_layer = Input(n=32*32, shape=image_shape, traces=True)\n",
    "sensory_layer = LIFNodes(n=32*32, shape=image_shape, traces=True)\n",
    "\n",
    "input_sensory_connection = Connection(\n",
    "                source=input_layer,\n",
    "                target=sensory_layer,\n",
    "                w = torch.ones((input_layer.n, sensory_layer.n)))\n",
    "\n",
    "network.add_layer(input_layer, 'simulated input')\n",
    "network.add_layer(sensory_layer, 'light-receptive neurons')\n",
    "network.add_connection(input_sensory_connection,\n",
    "                       source='simulated input',\n",
    "                       target='light-receptive neurons')\n",
    "\n",
    "\n",
    "dendrite_layers_container = []\n",
    "dendrite_connections_container = []\n",
    "\n",
    "dfs = dendrite_field_shape\n",
    "\n",
    "for iii in range(num_dendrite_layers):\n",
    "    dendrite_layers_container.append(LIFNodes(n=32*32, shape=dfs,\n",
    "                                    traces=True))\n",
    "    network.add_layer(dendrite_layers_container[iii], f\"feedback {iii}\")\n",
    "    \n",
    "    \n",
    "    weights = bernoulli(connection_prob*ones(dfs))*randn(dfs)\n",
    "    \n",
    "    dendrite_connections_container.append(Connection(\n",
    "                            source=dendrite_layers_container[iii],\n",
    "                            target=sensory_layer,\n",
    "                            w = weights ))\n",
    "    network.add_connection(dendrite_connections_container[iii],\n",
    "                           source=f\"feedback {iii}\",\n",
    "                           target='light-receptive neurons')\n",
    "    \n",
    "print(\"Topology with visual input, light-sensitive neurons, feedback paths:\")\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9ffe5de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (simulated input): Input()\n",
       "  (light-receptive neurons): LIFNodes()\n",
       "  (simulated input_to_light-receptive neurons): Connection(\n",
       "    (source): Input()\n",
       "    (target): LIFNodes()\n",
       "  )\n",
       "  (feedback 0): LIFNodes()\n",
       "  (feedback 0_to_light-receptive neurons): Connection(\n",
       "    (source): LIFNodes()\n",
       "    (target): LIFNodes()\n",
       "  )\n",
       "  (feedback 1): LIFNodes()\n",
       "  (feedback 1_to_light-receptive neurons): Connection(\n",
       "    (source): LIFNodes()\n",
       "    (target): LIFNodes()\n",
       "  )\n",
       "  (brain self-stim_to_dendrites 0): Connection(\n",
       "    (source): Input()\n",
       "    (target): LIFNodes()\n",
       "  )\n",
       "  (brain self-stim_to_dendrites 1): Connection(\n",
       "    (source): Input()\n",
       "    (target): LIFNodes()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_layer = Input(shape=dendrite_field_shape, traces=True)\n",
    "\n",
    "stim_dendrite_connections_container = []\n",
    "\n",
    "for jjj in range(num_dendrite_layers):\n",
    "    stim_dendrite_connections_container.append(Connection(\n",
    "                            source=stim_layer,\n",
    "                            target=dendrite_layers_container[jjj]))\n",
    "    \n",
    "    network.add_connection(stim_dendrite_connections_container[jjj],\n",
    "                           source= 'brain self-stim',\n",
    "                           target= f\"dendrites {jjj}\")\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83a98e",
   "metadata": {},
   "source": [
    "### Visualizing data with no feedback convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "971487c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MNIST(PoissonEncoder(time=total_timesteps, dt=dt),\n",
    "                      None,\n",
    "                      root = os.path.join(\".\", \"data\", \"MNIST\"),\n",
    "                      download=True,\n",
    "                      train=True,\n",
    "                      transform = transforms.Compose(\n",
    "                                  [transforms.Resize((32, 32)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Lambda(lambda x: x*intensity)])\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8dfe7e31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feedback 1 spikes': <bindsnet.network.monitors.Monitor at 0x7f9b656d2fe0>,\n",
       " 'simulated input spikes': <bindsnet.network.monitors.Monitor at 0x7f9b656d2f50>,\n",
       " 'light-receptive neurons spikes': <bindsnet.network.monitors.Monitor at 0x7f9b656d31f0>,\n",
       " 'feedback 0 spikes': <bindsnet.network.monitors.Monitor at 0x7f9b65770d60>,\n",
       " 'feedback 1 voltages': <bindsnet.network.monitors.Monitor at 0x7f9b6616f310>,\n",
       " 'light-receptive neurons voltages': <bindsnet.network.monitors.Monitor at 0x7f9b656d3370>,\n",
       " 'feedback 0 voltages': <bindsnet.network.monitors.Monitor at 0x7f9b65770430>}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes = { }\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer],\n",
    "                           state_vars = [\"s\"],\n",
    "                           time = total_timesteps)\n",
    "    network.add_monitor(spikes[layer], name = f\"{layer} spikes\")\n",
    "\n",
    "voltages = { }\n",
    "for layer in set(network.layers)-{\"simulated input\",'brain self-stim'}:\n",
    "    voltages[layer] = Monitor(network.layers[layer],\n",
    "                              state_vars = [\"v\"],\n",
    "                              time=total_timesteps)\n",
    "    network.add_monitor(voltages[layer], name = f\"{layer} voltages\")\n",
    "network.monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "934b5ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "training_pairs=[]\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "                        train_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,)\n",
    "\n",
    "datapoint = next(iter(train_dataloader))\n",
    "datum = datapoint[\"encoded_image\"].view(int( total_timesteps / dt),\n",
    "                                             1, 1, 32, 32)\n",
    "label = datapoint[\"label\"]\n",
    "\n",
    "network.run(inputs={\"simulated input\": datum}, time=total_timesteps)\n",
    "\n",
    "training_pairs.append([spikes[\"light-receptive neurons\"].get(\"s\").sum(0),\n",
    "                       label])\n",
    "\n",
    "training_pairs\n",
    "spikes[\"simulated input\"].get('s')\n",
    "datum.view(int(total_timesteps / dt), dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "08a3e009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = image_shape[0]*image_shape[1]\n",
    "inpt_axes, inpt_ims = plot_input(\n",
    "            datapoint[\"image\"].view(image_shape),\n",
    "            datum.view(int(total_timesteps / dt), dim).sum(0).view(image_shape),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "12eb48dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0 / 1 (0.00024271011352539062)\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "                        train_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "im_input, classes = next(iter(dataloader()))\n",
    "sim_input = {\"simulated_input\": im_input}\n",
    "\n",
    "network.run(inputs, time=total_)\n",
    "\n",
    "    for iii, batch in enumerate(tqdm(train_dataloader)):\n",
    "        if step > n_train:\n",
    "            break\n",
    "        inputs = {\"simulated input\": batch[\"encoded_image\"].view(time,\n",
    "                                                                batch_size\n",
    "                                                                1, 28, 28)}\n",
    "        if step % update_interval == 0 and step ~= 0:\n",
    "            label_vector = torch.tensor(labels, device=device)\n",
    "            \n",
    "        all_activity_pred = all_activity(spikes=spike_record,\n",
    "                                        assignments=assignments)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878cd6a",
   "metadata": {},
   "source": [
    "# Version 2: Feedback dendrites have spatially limited spans, relatively sparse connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c188a3",
   "metadata": {},
   "source": [
    "# Version 3: Feedback dendrites have unlimited span and connect to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6b791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
