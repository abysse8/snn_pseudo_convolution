{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d59bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time as t\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_assignments,\n",
    "    plot_input,\n",
    "    plot_performance,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    "    plot_weights,\n",
    ")\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_assignments, get_square_weights\n",
    "from bindsnet.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb0f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "n_neurons=100\n",
    "n_epochs=1\n",
    "n_test=10_000\n",
    "n_train=100\n",
    "n_workers=-1\n",
    "exc=22.5\n",
    "inh=120\n",
    "theta_plus=0.05\n",
    "time=250\n",
    "dt=1.0\n",
    "intensity=128\n",
    "progress_interval=1000\n",
    "update_interval=500\n",
    "train=True\n",
    "test=False\n",
    "plot=True\n",
    "gpu=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a240d526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device =  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "    device = \"cpu\"\n",
    "    if gpu:\n",
    "        gpu = False\n",
    "\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "print(\"Running on Device = \", device)\n",
    "\n",
    "# Determines number of workers to use\n",
    "if n_workers == -1:\n",
    "    n_workers = 0  # gpu * 4 * torch.cuda.device_count()\n",
    "\n",
    "if not train:\n",
    "    update_interval = n_test\n",
    "\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83dd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=784,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    norm=78.4,\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")\n",
    "# Directs network to GPU\n",
    "if gpu:\n",
    "    network.to(\"cuda\")\n",
    "\n",
    "# Load MNIST data.\n",
    "train_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "n_classes = 10\n",
    "assignments = -torch.ones(n_neurons, device=device)\n",
    "proportions = torch.zeros((n_neurons, n_classes), device=device)\n",
    "rates = torch.zeros((n_neurons, n_classes), device=device)\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor = Monitor(\n",
    "    network.layers[\"Ae\"], [\"v\"], time=int(time / dt), device=device\n",
    ")\n",
    "inh_voltage_monitor = Monitor(\n",
    "    network.layers[\"Ai\"], [\"v\"], time=int(time / dt), device=device\n",
    ")\n",
    "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
    "\n",
    "# Set up monitors for spikes and voltages\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(\n",
    "        network.layers[layer], state_vars=[\"s\"], time=int(time / dt), device=device\n",
    "    )\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(\n",
    "        network.layers[layer], state_vars=[\"v\"], time=int(time / dt), device=device\n",
    "    )\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\n",
    "\n",
    "inpt_ims, inpt_axes = None, None\n",
    "spike_ims, spike_axes = None, None\n",
    "weights_im = None\n",
    "assigns_im = None\n",
    "perf_ax = None\n",
    "voltage_axes, voltage_ims = None, None\n",
    "weights_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "509713ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                               | 11/60000 [00:15<23:51:09,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "n_train = 10\n",
    "\n",
    "print(\"\\nBegin training.\\n\")\n",
    "start = t()\n",
    "for epoch in range(n_epochs):\n",
    "    labels = []\n",
    "\n",
    "    if epoch % progress_interval == 0:\n",
    "        print(\"Progress: %d / %d (%.4f seconds)\" % (epoch, n_epochs, t() - start))\n",
    "        start = t()\n",
    "\n",
    "    # Create a dataloader to iterate and batch data\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True, num_workers=n_workers, pin_memory=gpu\n",
    "    )\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader)):\n",
    "        if step > n_train:\n",
    "            break\n",
    "        # Get next input sample.\n",
    "        ############################################################################\n",
    "        stim = torch.zeros((time, 1, 100)).byte()\n",
    "        inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "        ################################################################################\n",
    "        \n",
    "        if gpu:\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "        if step % update_interval == 0 and step > 0:\n",
    "            # Convert the array of labels into a tensor\n",
    "            label_tensor = torch.tensor(labels, device=device)\n",
    "\n",
    "            # Get network predictions.\n",
    "            all_activity_pred = all_activity(\n",
    "                spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "            )\n",
    "            proportion_pred = proportion_weighting(\n",
    "                spikes=spike_record,\n",
    "                assignments=assignments,\n",
    "                proportions=proportions,\n",
    "                n_labels=n_classes,\n",
    "            )\n",
    "\n",
    "            # Compute network accuracy according to available classification strategies.\n",
    "            accuracy[\"all\"].append(\n",
    "                100\n",
    "                * torch.sum(label_tensor.long() == all_activity_pred).item()\n",
    "                / len(label_tensor)\n",
    "            )\n",
    "            accuracy[\"proportion\"].append(\n",
    "                100\n",
    "                * torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "                / len(label_tensor)\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "                % (\n",
    "                    accuracy[\"all\"][-1],\n",
    "                    np.mean(accuracy[\"all\"]),\n",
    "                    np.max(accuracy[\"all\"]),\n",
    "                )\n",
    "            )\n",
    "            print(\n",
    "                \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f\"\n",
    "                \" (best)\\n\"\n",
    "                % (\n",
    "                    accuracy[\"proportion\"][-1],\n",
    "                    np.mean(accuracy[\"proportion\"]),\n",
    "                    np.max(accuracy[\"proportion\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Assign labels to excitatory layer neurons.\n",
    "            assignments, proportions, rates = assign_labels(\n",
    "                spikes=spike_record,\n",
    "                labels=label_tensor,\n",
    "                n_labels=n_classes,\n",
    "                rates=rates,\n",
    "            )\n",
    "\n",
    "            labels = []\n",
    "\n",
    "        labels.append(batch[\"label\"])\n",
    "\n",
    "        # Run the network on the input.\n",
    "        network.run(inputs=inputs, time=time)\n",
    "        \n",
    "        ##########################################################\n",
    "        \n",
    "        weights_info = []\n",
    "\n",
    "\n",
    "        ##########################################################\n",
    "\n",
    "        # Get voltage recording.\n",
    "        exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "        inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "        # Add to spikes recording.\n",
    "        spike_record[step % update_interval] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "        # Optionally plot various simulation information.\n",
    "        if plot:\n",
    "            \n",
    "            clear_output(wait = True)\n",
    "            \n",
    "            \n",
    "            image = batch[\"image\"].view(28, 28)\n",
    "            inpt = inputs[\"X\"].view(time, 784).sum(0).view(28, 28)\n",
    "            input_exc_weights = network.connections[(\"Ae\", \"Ai\")].w\n",
    "            square_weights = get_square_weights(\n",
    "                input_exc_weights.view(100, n_neurons), n_sqrt, 10\n",
    "            )\n",
    "            square_assignments = get_square_assignments(assignments, n_sqrt)\n",
    "            spikes_ = {layer: spikes[layer].get(\"s\") for layer in spikes}\n",
    "            voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
    "            inpt_axes, inpt_ims = plot_input(\n",
    "                image, inpt, label=batch[\"label\"], axes=inpt_axes, ims=inpt_ims\n",
    "            )\n",
    "            spike_ims, spike_axes = plot_spikes(spikes_, ims=spike_ims, axes=spike_axes)\n",
    "            weights_im = plot_weights(square_weights, im=weights_im)\n",
    "            assigns_im = plot_assignments(square_assignments, im=assigns_im)\n",
    "            perf_ax = plot_performance(accuracy, x_scale=update_interval, ax=perf_ax)\n",
    "            voltage_ims, voltage_axes = plot_voltages(\n",
    "                voltages, ims=voltage_ims, axes=voltage_axes, plot_type=\"line\"\n",
    "            )\n",
    "            print(weights_info)\n",
    "            #update_ratio = previous_grad/float(torch.mean(get_square_weights(input_exc_weights.view(100, n_neurons), n_sqrt, 10)))\n",
    "            #if update_ratio > 1.05:\n",
    "            #    network.connections['light-receptive neurons', 'output neurons'].update_rule.nu[1] = network.connections['light-receptive neurons', 'output neurons'].update_rule.nu[1]*1.01\n",
    "            #elif update_ratio < 0.95:\n",
    "            #    network.connections['light-receptive neurons', 'output neurons'].update_rule.nu[1] = network.connections['light-receptive neurons', 'output neurons'].update_rule.nu[1]/1.01\n",
    "            #print(f\"Old nu: {list(og_nu)}, Nu nu: {list(network.connections['light-receptive neurons', 'output neurons'].update_rule.nu)}\")\n",
    "            #print(f\"Update ratio: {update_ratio}\")\n",
    "            #previous_grad = torch.mean(get_square_weights(input_exc_weights.view(100, n_neurons), n_sqrt, 10))\n",
    "        network.reset_state_variables()  # Reset state variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5e74608",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy = np.array(spikes_['X'].sum(dim=0)[0][0].cpu())\n",
    "xxx = np.array(torch.tensor(spikes_['Ae'].cpu(), dtype=int).sum(dim=0).reshape(10,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9635418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin testing\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test progress: 100%|████████████████████| 10000/10000 [1:17:49<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All activity accuracy: 0.10\n",
      "Proportion weighting accuracy: 0.10 \n",
      "\n",
      "Progress: 1 / 1 (4670.3896 seconds)\n",
      "Testing complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data.\n",
    "test_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": 0, \"proportion\": 0}\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros((1, int(time / dt), n_neurons), device=device)\n",
    "\n",
    "# Train the network.\n",
    "print(\"\\nBegin testing\\n\")\n",
    "network.train(mode=False)\n",
    "start = t()\n",
    "\n",
    "pbar = tqdm(total=n_test)\n",
    "for step, batch in enumerate(test_dataset):\n",
    "    if step >= n_test:\n",
    "        break\n",
    "    # Get next input sample.\n",
    "    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "    if gpu:\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # Run the network on the input.\n",
    "    network.run(inputs=inputs, time=time)\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "    # Convert the array of labels into a tensor\n",
    "    label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
    "\n",
    "    # Get network predictions.\n",
    "    all_activity_pred = all_activity(\n",
    "        spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "    )\n",
    "    proportion_pred = proportion_weighting(\n",
    "        spikes=spike_record,\n",
    "        assignments=assignments,\n",
    "        proportions=proportions,\n",
    "        n_labels=n_classes,\n",
    "    )\n",
    "\n",
    "    # Compute network accuracy according to available classification strategies.\n",
    "    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
    "    accuracy[\"proportion\"] += float(\n",
    "        torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "    )\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "    pbar.set_description_str(\"Test progress: \")\n",
    "    pbar.update()\n",
    "\n",
    "print(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / n_test))\n",
    "print(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / n_test))\n",
    "\n",
    "print(\"Progress: %d / %d (%.4f seconds)\" % (epoch + 1, n_epochs, t() - start))\n",
    "print(\"Testing complete.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35fcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
